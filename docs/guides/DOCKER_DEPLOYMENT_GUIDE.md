# Dockerç¯å¢ƒéƒ¨ç½²å®Œæ•´æŒ‡å—

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11 Pro, Enterprise, æˆ– Education (64ä½)
- **å†…å­˜**: è‡³å°‘8GB RAM (æ¨è16GB)
- **å­˜å‚¨**: è‡³å°‘20GBå¯ç”¨ç©ºé—´
- **CPU**: æ”¯æŒè™šæ‹ŸåŒ–æŠ€æœ¯

### 2. å¿…éœ€è½¯ä»¶
- **Docker Desktop for Windows**
- **WSL 2** (Windows Subsystem for Linux)

## ğŸš€ å®‰è£…æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…WSL 2

```powershell
# ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡ŒPowerShell
wsl --install

# æˆ–è€…æ‰‹åŠ¨å®‰è£…
wsl --install -d Ubuntu
```

### ç¬¬äºŒæ­¥ï¼šå®‰è£…Docker Desktop

1. è®¿é—® [Dockerå®˜ç½‘](https://www.docker.com/products/docker-desktop)
2. ä¸‹è½½ Docker Desktop for Windows
3. è¿è¡Œå®‰è£…ç¨‹åº
4. å®‰è£…è¿‡ç¨‹ä¸­é€‰æ‹©å¯ç”¨WSL 2åç«¯
5. é‡å¯è®¡ç®—æœº

### ç¬¬ä¸‰æ­¥ï¼šé…ç½®Docker (å¯é€‰GPUæ”¯æŒ)

#### GPUæ”¯æŒ (NVIDIAæ˜¾å¡)
```powershell
# å®‰è£…NVIDIA Container Toolkit
# ä»NVIDIAå®˜ç½‘ä¸‹è½½å¹¶å®‰è£…:
# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
```

### ç¬¬å››æ­¥ï¼šéªŒè¯å®‰è£…

```powershell
# æ£€æŸ¥Dockerç‰ˆæœ¬
docker --version

# æ£€æŸ¥Dockeræ˜¯å¦è¿è¡Œ
docker info

# è¿è¡Œæµ‹è¯•å®¹å™¨
docker run hello-world
```

## ğŸ¯ éƒ¨ç½²llama.cppæœåŠ¡

### è‡ªåŠ¨éƒ¨ç½² (æ¨è)

```powershell
# è¿è¡Œéƒ¨ç½²è„šæœ¬
.\deploy_docker.bat

# è„šæœ¬ä¼šè‡ªåŠ¨:
# 1. æ£€æŸ¥Dockerç¯å¢ƒ
# 2. æ£€æŸ¥NVIDIAæ”¯æŒ
# 3. éªŒè¯æ¨¡å‹æ–‡ä»¶
# 4. æ„å»ºå¹¶å¯åŠ¨å®¹å™¨
```

### æ‰‹åŠ¨éƒ¨ç½²

```powershell
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨GPUç‰ˆæœ¬
docker-compose up -d llama-cpp-image-service

# æˆ–å¯åŠ¨CPUç‰ˆæœ¬
docker-compose up -d llama-cpp-image-service-cpu

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

## ğŸ“Š æœåŠ¡è®¿é—®

### ç«¯å£æ˜ å°„
- **GPUç‰ˆæœ¬**: `http://localhost:5005`
- **CPUç‰ˆæœ¬**: `http://localhost:5006`

### APIç«¯ç‚¹
```bash
# å¥åº·æ£€æŸ¥
GET http://localhost:5005/api/native_llama_cpp_image/health

# æ¨¡å‹åˆ—è¡¨
GET http://localhost:5005/api/native_llama_cpp_image/models

# åŠ è½½æ¨¡å‹
POST http://localhost:5005/api/native_llama_cpp_image/load_model
{
  "model": "z-image-turbo-art"
}

# ç”Ÿæˆå›¾åƒ
POST http://localhost:5005/api/native_llama_cpp_image/generate
{
  "prompt": "ç¾ä¸½çš„å±±æ°´é£æ™¯",
  "width": 512,
  "height": 512,
  "steps": 20
}
```

## ğŸ› ï¸ ç®¡ç†å‘½ä»¤

```powershell
# åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose down

# é‡å¯æœåŠ¡
docker-compose restart

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs

# è¿›å…¥å®¹å™¨
docker exec -it llama-cpp-image-service bash

# åˆ é™¤é•œåƒ
docker-compose down --rmi all
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Docker Desktopæ— æ³•å¯åŠ¨**
   - ç¡®ä¿å¯ç”¨äº†WSL 2
   - æ£€æŸ¥Windowsè™šæ‹ŸåŒ–åŠŸèƒ½æ˜¯å¦å¼€å¯
   - é‡å¯Docker DesktopæœåŠ¡

2. **å®¹å™¨æ„å»ºå¤±è´¥**
   ```powershell
   # æ¸…ç†Dockerç¼“å­˜
   docker system prune -a
   
   # é‡æ–°æ„å»º
   docker-compose build --no-cache
   ```

3. **GPUä¸å¯ç”¨**
   - ç¡®è®¤å®‰è£…äº†NVIDIA Container Toolkit
   - æ£€æŸ¥Dockerè®¾ç½®ä¸­çš„Resources â†’ WSL Integration
   - éªŒè¯NVIDIAé©±åŠ¨ç‰ˆæœ¬

4. **ç«¯å£å†²çª**
   - ä¿®æ”¹docker-compose.ymlä¸­çš„ç«¯å£æ˜ å°„
   - æ£€æŸ¥å…¶ä»–æœåŠ¡æ˜¯å¦å ç”¨5005/5006ç«¯å£

### æ€§èƒ½ä¼˜åŒ–

```powershell
# ä¸ºDockeråˆ†é…æ›´å¤šèµ„æº
# åœ¨Docker Desktop â†’ Settings â†’ Resourcesä¸­è°ƒæ•´:
# - CPUs: 4-8æ ¸
# - Memory: 8-16GB
# - Swap: 2-4GB
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| ç¯å¢ƒ | é¦–æ¬¡å¯åŠ¨ | å›¾åƒç”Ÿæˆ | èµ„æºå ç”¨ | æ˜“ç”¨æ€§ |
|------|----------|----------|----------|--------|
| Docker GPU | 5-10åˆ†é’Ÿ | 3-8ç§’ | é«˜ | â­â­â­â­â­ |
| Docker CPU | 5-10åˆ†é’Ÿ | 15-30ç§’ | ä¸­ | â­â­â­â­ |
| æœ¬åœ°ç¼–è¯‘ | 30åˆ†é’Ÿ+ | 3-8ç§’ | ä¸­ | â­â­â­ |

## ğŸ‰ éªŒè¯éƒ¨ç½²

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯éƒ¨ç½²æ˜¯å¦æˆåŠŸï¼š

```powershell
python test_docker_deployment.py
```

è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æµ‹è¯•æ‰€æœ‰è¿è¡Œä¸­çš„DockeræœåŠ¡ã€‚

---
*æ–‡æ¡£ç‰ˆæœ¬: 1.0*  
*æ›´æ–°æ—¶é—´: 2026å¹´2æœˆ15æ—¥*